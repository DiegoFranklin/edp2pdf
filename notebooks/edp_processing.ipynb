{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_src import import_src\n",
    "import_src()\n",
    "\n",
    "from src.image_process.image_io import LoadImage, WriteImage\n",
    "import src.image_process.pre_process as prep\n",
    "import src.image_process.mask.mask_getters as maskget\n",
    "from src.image_process.edp_center.centroid import get_centroid\n",
    "from src.image_process.edp_center.center_optimization.opt_funcs import Distance\n",
    "from src.image_process.edp_center.center_optimization.optimization import optimize_center\n",
    "from src.image_process.edp_center.autocorrelation import AutoCorrelation\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Iterable, List, Union, Callable, TypeVar, Tuple\n",
    "from collections.abc import Iterable as IterableABC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar(\"T\")\n",
    "U = TypeVar(\"U\")\n",
    "\n",
    "def batch_run(batch_input: Iterable[T], operate_single: Callable[[T], U]) -> List[U]:\n",
    "    \"\"\"\n",
    "    Applies the given single-item function to each item in the batch.\n",
    "\n",
    "    Args:\n",
    "        batch_input: An iterable of inputs to process.\n",
    "        operate_single: A function that processes a single input of type `T`.\n",
    "\n",
    "    Returns:\n",
    "        A list of processed inputs.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If any element in the iterable is not of the expected type.\n",
    "    \"\"\"\n",
    "    # Check that all elements in the iterable are of the expected type\n",
    "    first_element_type = type(next(iter(batch_input)))\n",
    "    if not all(isinstance(x, first_element_type) for x in batch_input):\n",
    "        raise TypeError(f\"All elements in the iterable must be of type {first_element_type.__name__}.\")\n",
    "    return [operate_single(x) for x in batch_input]\n",
    "\n",
    "def make_batch_version(operate_single: Callable[[T], U]) -> Callable[[Union[Iterable[T], T]], Union[List[U], U]]:\n",
    "    \"\"\"\n",
    "    Creates a batch-compatible version of a single-item processing function.\n",
    "\n",
    "    Args:\n",
    "        operate_single: A function that processes a single input of type `T`.\n",
    "\n",
    "    Returns:\n",
    "        A function that can process either a single input or an iterable of inputs.\n",
    "    \"\"\"\n",
    "    def batch_version(input: Union[Iterable[T], T]) -> Union[List[U], U]:\n",
    "        \"\"\"\n",
    "        Processes either a single input or an iterable of inputs.\n",
    "\n",
    "        Args:\n",
    "            input: A single input or an iterable of inputs.\n",
    "\n",
    "        Returns:\n",
    "            The processed input or a list of processed inputs.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If the input is not of the expected type.\n",
    "            ValueError: If the iterable is empty.\n",
    "        \"\"\"\n",
    "        if not isinstance(input, IterableABC) or isinstance(input, (str, bytes)):\n",
    "            # Single item\n",
    "            return operate_single(input)\n",
    "        elif isinstance(input, IterableABC):\n",
    "            # Batch processing\n",
    "            if not input:\n",
    "                raise ValueError(\"The input iterable must not be empty.\")\n",
    "            return batch_run(input, operate_single)\n",
    "        else:\n",
    "            # Unsupported type\n",
    "            raise TypeError(\n",
    "                f\"Input must be of type {T} or an iterable of {T}, \"\n",
    "                f\"but got {type(input).__name__}.\"\n",
    "            )\n",
    "\n",
    "    return batch_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single(path: str) -> np.ndarray:\n",
    "    return LoadImage(path).data\n",
    "\n",
    "load = make_batch_version(load_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single(data):\n",
    "    median_filter = prep.MedianFilter(kernel_size=5)\n",
    "    all_positive = prep.AllPositive()\n",
    "\n",
    "    pre_processors = [median_filter, all_positive]\n",
    "\n",
    "    pre_pipe = prep.PreProcessPipe(pre_processors=pre_processors)\n",
    "    data = pre_pipe.pre_process_pipe(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "preprocess = make_batch_version(preprocess_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_single(data):\n",
    "    mean_mask = maskget.MeanTreshMask(.1)\n",
    "\n",
    "    mask = maskget.superpose_masks(data, [mean_mask])\n",
    "\n",
    "    return mask\n",
    "\n",
    "get_mask = make_batch_version(get_mask_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from functools import partial\n",
    "\n",
    "def autocorr(data, mask):\n",
    "    ac = AutoCorrelation(data, mask)\n",
    "    center, _ = ac.compute()\n",
    "    return center\n",
    "\n",
    "def first_guess(data, mask, method: str = \"centroid\"):\n",
    "    \"\"\"\n",
    "    Computes the first guess for the center using the specified method.\n",
    "\n",
    "    Args:\n",
    "        data: Input data (e.g., a numpy array).\n",
    "        mask: Mask for the input data.\n",
    "        method: Method to use for computing the first guess. Supported values are \"autocorrelation\" and \"centroid\".\n",
    "\n",
    "    Returns:\n",
    "        The computed first guess for the center.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the method is not supported.\n",
    "    \"\"\"\n",
    "    methods = {\n",
    "        \"autocorrelation\": lambda: autocorr(data, mask),\n",
    "        \"centroid\": lambda: get_centroid(data),\n",
    "    }\n",
    "\n",
    "    if method not in methods:\n",
    "        raise ValueError(f\"Unknown first guess method: {method}\")\n",
    "\n",
    "    return methods[method]()\n",
    "\n",
    "def find_center_single(data_mask: Tuple, distance_metric: str = \"manhattan\", first_guess_method: str = \"centroid\"):\n",
    "    \"\"\"\n",
    "    Finds the center of the input data using the specified distance metric and first guess method.\n",
    "\n",
    "    Args:\n",
    "        data_mask: A tuple containing the input data and mask.\n",
    "        distance_metric: The distance metric to use for optimization. Defaults to \"manhattan\".\n",
    "        first_guess_method: The method to use for computing the first guess. Defaults to \"centroid\".\n",
    "\n",
    "    Returns:\n",
    "        The computed center.\n",
    "    \"\"\"\n",
    "    data, mask = data_mask\n",
    "\n",
    "    # Compute the first guess\n",
    "    initial_guess = first_guess(data, mask, method=first_guess_method)\n",
    "\n",
    "    # Create the penalty function\n",
    "    penalty_func = Distance(data, mask, distance_metric=distance_metric).get_penalty_func()\n",
    "\n",
    "    # Optimize the center\n",
    "    center = optimize_center(penalty_func, data.shape, initial_guess=initial_guess)\n",
    "\n",
    "    return center\n",
    "\n",
    "# Configuration\n",
    "first_guess_method = \"centroid\"\n",
    "distance_metric = \"manhattan\"\n",
    "\n",
    "# Create the batch version of find_center_single\n",
    "find_center = make_batch_version(\n",
    "    partial(find_center_single, distance_metric=distance_metric, first_guess_method=first_guess_method)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = \"../raw_data/samples/\"\n",
    "samples_file_names = os.listdir(samples_path)\n",
    "samples_paths = [samples_path + x for x in samples_file_names]\n",
    "\n",
    "calibration_samples_path = \"../raw_data/gold/\"\n",
    "calibration_file_names = os.listdir(calibration_samples_path)\n",
    "calibration_paths = [calibration_samples_path + x for x in gold_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing data...\n",
      "Getting masks...\n",
      "Finding centers...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "loaded_data = load(all_paths)\n",
    "\n",
    "print(\"Preprocessing data...\")\n",
    "preprocessed_data = preprocess(loaded_data)\n",
    "\n",
    "print(\"Getting masks...\")\n",
    "masks = get_mask(preprocessed_data)\n",
    "\n",
    "print(\"Finding centers...\")\n",
    "centers = find_center([(d, m) for d, m in zip(preprocessed_data, masks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../raw_data/samples/Carbono_beamstopper_Dia9_original.dm3\n",
      "(1328.0036977709453, 1354.9999998283872)\n",
      "../raw_data/samples/Cu120W_Zr144W_beamstopper_original.dm3\n",
      "(1375.4204734722014, 1346.999995678504)\n",
      "../raw_data/samples/Cu30W_beamstopper_original.dm3\n",
      "(1350.001616883015, 1382.9999978076628)\n",
      "../raw_data/samples/Cu30W_Zr100W_beamstopper_original.dm3\n",
      "(1320.9999991985503, 1363.0000045854842)\n",
      "../raw_data/samples/Cu30W_Zr120W_beamstopper_original.dm3\n",
      "(1341.0000000097098, 1339.9999948130157)\n",
      "../raw_data/samples/Cu30W_Zr210W_beamstopper_original.dm3\n",
      "(1357.9999967504048, 1390.9999990948202)\n",
      "../raw_data/samples/Cu60W_Zr72W_beamstopper_original.dm3\n",
      "(1355.0000000081618, 1401.0073673419215)\n",
      "../raw_data/samples/Zr30W_beamstopper_original.dm3\n",
      "(1333.9999998285296, 1348.99998589857)\n",
      "../raw_data/gold/Ouro_beamstopper_final_original_Dia8.dm3\n",
      "(1356.999826273311, 1380.9999986035434)\n",
      "../raw_data/gold/Ouro_beamstopper_inicial_original_Dia8.dm3\n",
      "(1091.9999822907412, 1103.9999994456232)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "to_print=centers\n",
    "\n",
    "for i in range(len(to_print)):\n",
    "    print(all_paths[i])\n",
    "    if isinstance(to_print[i], np.ndarray):\n",
    "        plt.imshow(to_print[i])\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(to_print[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edp2pdf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
